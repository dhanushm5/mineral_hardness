{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c733751",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-03T17:12:29.559382Z",
     "iopub.status.busy": "2024-11-03T17:12:29.559034Z",
     "iopub.status.idle": "2024-11-03T17:12:47.339160Z",
     "shell.execute_reply": "2024-11-03T17:12:47.338031Z"
    },
    "papermill": {
     "duration": 17.787853,
     "end_time": "2024-11-03T17:12:47.341456",
     "exception": false,
     "start_time": "2024-11-03T17:12:29.553603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (4.0.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.3)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.30)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.2)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\r\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     15000 non-null  int64  \n",
      " 1   Hardness               15000 non-null  float64\n",
      " 2   allelectrons_Total     15000 non-null  float64\n",
      " 3   density_Total          15000 non-null  float64\n",
      " 4   allelectrons_Average   15000 non-null  float64\n",
      " 5   val_e_Average          15000 non-null  float64\n",
      " 6   atomicweight_Average   15000 non-null  float64\n",
      " 7   ionenergy_Average      15000 non-null  float64\n",
      " 8   el_neg_chi_Average     15000 non-null  float64\n",
      " 9   R_vdw_element_Average  15000 non-null  float64\n",
      " 10  R_cov_element_Average  15000 non-null  float64\n",
      " 11  zaratio_Average        15000 non-null  float64\n",
      " 12  density_Average        15000 non-null  float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 1.5 MB\n",
      "/kaggle/input/round-2-nexus-recruitment/sample_submission.csv\n",
      "/kaggle/input/round-2-nexus-recruitment/train.csv\n",
      "/kaggle/input/round-2-nexus-recruitment/test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import optuna\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# Load Data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "train_df.head()\n",
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cf228c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:12:47.350893Z",
     "iopub.status.busy": "2024-11-03T17:12:47.350559Z",
     "iopub.status.idle": "2024-11-03T17:12:47.398538Z",
     "shell.execute_reply": "2024-11-03T17:12:47.397759Z"
    },
    "papermill": {
     "duration": 0.054966,
     "end_time": "2024-11-03T17:12:47.400648",
     "exception": false,
     "start_time": "2024-11-03T17:12:47.345682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def create_features(df):\n",
    "    df['density_ratio'] = df['density_Total'] / df['density_Average']\n",
    "    df['electron_density_ratio'] = df['allelectrons_Total'] / df['density_Total']\n",
    "    df['weight_density_ratio'] = df['atomicweight_Average'] / df['density_Average']\n",
    "    df['ionenergy_density'] = df['ionenergy_Average'] / df['density_Average']\n",
    "    df['log_density'] = np.log1p(df['density_Total'])\n",
    "    df['log_weight'] = np.log1p(df['atomicweight_Average'])\n",
    "    df['energy_density_product'] = df['ionenergy_Average'] * df['density_Total']\n",
    "    df['electron_weight_ratio'] = df['allelectrons_Total'] / df['atomicweight_Average']\n",
    "    df['total_energy'] = df['allelectrons_Total'] * df['ionenergy_Average']\n",
    "    return df\n",
    "\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "\n",
    "# Handle infinite values\n",
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "train_df.fillna(train_df.mean(), inplace=True)\n",
    "test_df.fillna(test_df.mean(), inplace=True)\n",
    "\n",
    "# Prepare Data\n",
    "X = train_df.drop(['Hardness', 'id'], axis=1)\n",
    "y = train_df['Hardness']\n",
    "X_test = test_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b703996b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:12:47.410120Z",
     "iopub.status.busy": "2024-11-03T17:12:47.409764Z",
     "iopub.status.idle": "2024-11-03T17:12:47.526393Z",
     "shell.execute_reply": "2024-11-03T17:12:47.525384Z"
    },
    "papermill": {
     "duration": 0.123684,
     "end_time": "2024-11-03T17:12:47.528645",
     "exception": false,
     "start_time": "2024-11-03T17:12:47.404961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75866d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:12:47.538661Z",
     "iopub.status.busy": "2024-11-03T17:12:47.537859Z",
     "iopub.status.idle": "2024-11-03T17:12:47.747465Z",
     "shell.execute_reply": "2024-11-03T17:12:47.746479Z"
    },
    "papermill": {
     "duration": 0.217193,
     "end_time": "2024-11-03T17:12:47.750035",
     "exception": false,
     "start_time": "2024-11-03T17:12:47.532842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225c2afa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:12:47.761540Z",
     "iopub.status.busy": "2024-11-03T17:12:47.760884Z",
     "iopub.status.idle": "2024-11-03T17:12:47.778890Z",
     "shell.execute_reply": "2024-11-03T17:12:47.778063Z"
    },
    "papermill": {
     "duration": 0.025894,
     "end_time": "2024-11-03T17:12:47.780808",
     "exception": false,
     "start_time": "2024-11-03T17:12:47.754914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Objective Function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameters\n",
    "    hidden_size = trial.suggest_int('hidden_size', 128, 1024)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    activation_name = trial.suggest_categorical('activation', ['ReLU', 'LeakyReLU', 'ELU', 'GELU'])\n",
    "    \n",
    "    # Activation Function\n",
    "    activation = getattr(nn, activation_name)()\n",
    "    \n",
    "    # Model Definition\n",
    "    class NeuralNet(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(NeuralNet, self).__init__()\n",
    "            layers = []\n",
    "            in_features = input_dim\n",
    "            for _ in range(num_layers):\n",
    "                layers.append(nn.Linear(in_features, hidden_size))\n",
    "                layers.append(activation)\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                in_features = hidden_size\n",
    "            layers.append(nn.Linear(hidden_size, 1))\n",
    "            self.model = nn.Sequential(*layers)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "    \n",
    "    # Model and Optimizer\n",
    "    model = NeuralNet(input_dim=X_train.shape[1])\n",
    "    model.to(device)\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Data Loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Training Loop\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_dataset)\n",
    "        \n",
    "        # Report\n",
    "        trial.report(val_loss, epoch)\n",
    "        \n",
    "        # Prune\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fcff72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:12:47.790102Z",
     "iopub.status.busy": "2024-11-03T17:12:47.789384Z",
     "iopub.status.idle": "2024-11-03T17:19:14.394190Z",
     "shell.execute_reply": "2024-11-03T17:19:14.393125Z"
    },
    "papermill": {
     "duration": 386.6116,
     "end_time": "2024-11-03T17:19:14.396278",
     "exception": false,
     "start_time": "2024-11-03T17:12:47.784678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-03 17:12:47,792] A new study created in memory with name: no-name-a295f35a-cdc7-41dc-9bb0-d56c27ae8cc9\n",
      "/tmp/ipykernel_23/961124132.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/tmp/ipykernel_23/961124132.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
      "[I 2024-11-03 17:13:09,513] Trial 0 finished with value: 1.050882129351298 and parameters: {'hidden_size': 376, 'num_layers': 1, 'dropout_rate': 0.18881415550890318, 'learning_rate': 0.0034674783138713694, 'weight_decay': 2.3764610150734924e-05, 'batch_size': 64, 'activation': 'ReLU'}. Best is trial 0 with value: 1.050882129351298.\n",
      "/tmp/ipykernel_23/961124132.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/tmp/ipykernel_23/961124132.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
      "[I 2024-11-03 17:13:27,091] Trial 1 finished with value: 1.131344741821289 and parameters: {'hidden_size': 159, 'num_layers': 5, 'dropout_rate': 0.18008498622670782, 'learning_rate': 1.263928208008661e-05, 'weight_decay': 1.2396321775875055e-06, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 0 with value: 1.050882129351298.\n",
      "[I 2024-11-03 17:13:56,004] Trial 2 finished with value: 1.1759769077301025 and parameters: {'hidden_size': 321, 'num_layers': 5, 'dropout_rate': 0.3832472449841799, 'learning_rate': 0.0041113446052908394, 'weight_decay': 5.443705474829396e-06, 'batch_size': 64, 'activation': 'GELU'}. Best is trial 0 with value: 1.050882129351298.\n",
      "[I 2024-11-03 17:14:34,016] Trial 3 finished with value: 0.9813557370503744 and parameters: {'hidden_size': 890, 'num_layers': 2, 'dropout_rate': 0.12161424428266182, 'learning_rate': 4.2052587410959206e-05, 'weight_decay': 2.8358340925720687e-05, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:14:49,399] Trial 4 finished with value: 0.9927651022275289 and parameters: {'hidden_size': 410, 'num_layers': 3, 'dropout_rate': 0.41031668460521054, 'learning_rate': 0.00046405905024650564, 'weight_decay': 0.00014703979912622723, 'batch_size': 128, 'activation': 'ReLU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:15:03,515] Trial 5 finished with value: 0.9922106029192607 and parameters: {'hidden_size': 573, 'num_layers': 2, 'dropout_rate': 0.07050850620349347, 'learning_rate': 0.0010804668759486985, 'weight_decay': 0.0017124606609873001, 'batch_size': 128, 'activation': 'LeakyReLU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:15:03,835] Trial 6 pruned. \n",
      "[I 2024-11-03 17:15:04,173] Trial 7 pruned. \n",
      "[I 2024-11-03 17:15:04,967] Trial 8 pruned. \n",
      "[I 2024-11-03 17:15:05,259] Trial 9 pruned. \n",
      "[I 2024-11-03 17:15:05,947] Trial 10 pruned. \n",
      "[I 2024-11-03 17:15:44,454] Trial 11 finished with value: 1.0138469247817994 and parameters: {'hidden_size': 723, 'num_layers': 2, 'dropout_rate': 0.08451900713540561, 'learning_rate': 0.0007280985658679978, 'weight_decay': 0.005200814860386872, 'batch_size': 32, 'activation': 'LeakyReLU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:15:45,255] Trial 12 pruned. \n",
      "[I 2024-11-03 17:15:45,961] Trial 13 pruned. \n",
      "[I 2024-11-03 17:16:10,580] Trial 14 finished with value: 1.0052929134368898 and parameters: {'hidden_size': 873, 'num_layers': 3, 'dropout_rate': 0.009114342337034287, 'learning_rate': 0.00022352845128602137, 'weight_decay': 0.009402628547770324, 'batch_size': 64, 'activation': 'ReLU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:16:10,930] Trial 15 pruned. \n",
      "[I 2024-11-03 17:16:12,038] Trial 16 pruned. \n",
      "[I 2024-11-03 17:16:12,862] Trial 17 pruned. \n",
      "[I 2024-11-03 17:16:13,255] Trial 18 pruned. \n",
      "[I 2024-11-03 17:16:13,685] Trial 19 pruned. \n",
      "[I 2024-11-03 17:16:14,010] Trial 20 pruned. \n",
      "[I 2024-11-03 17:16:14,388] Trial 21 pruned. \n",
      "[I 2024-11-03 17:16:14,736] Trial 22 pruned. \n",
      "[I 2024-11-03 17:16:15,342] Trial 23 pruned. \n",
      "[I 2024-11-03 17:16:15,712] Trial 24 pruned. \n",
      "[I 2024-11-03 17:16:16,599] Trial 25 pruned. \n",
      "[I 2024-11-03 17:16:18,354] Trial 26 pruned. \n",
      "[I 2024-11-03 17:16:18,657] Trial 27 pruned. \n",
      "[I 2024-11-03 17:17:01,877] Trial 28 finished with value: 0.9972561906178792 and parameters: {'hidden_size': 397, 'num_layers': 3, 'dropout_rate': 0.2930337357229269, 'learning_rate': 0.00024488545080281356, 'weight_decay': 6.591990741638941e-05, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:17:02,323] Trial 29 pruned. \n",
      "[I 2024-11-03 17:17:02,809] Trial 30 pruned. \n",
      "[I 2024-11-03 17:17:03,687] Trial 31 pruned. \n",
      "[I 2024-11-03 17:17:05,464] Trial 32 pruned. \n",
      "[I 2024-11-03 17:17:06,442] Trial 33 pruned. \n",
      "[I 2024-11-03 17:17:07,332] Trial 34 pruned. \n",
      "[I 2024-11-03 17:17:25,164] Trial 35 finished with value: 1.0021015822092691 and parameters: {'hidden_size': 296, 'num_layers': 5, 'dropout_rate': 0.1736994947134775, 'learning_rate': 0.00314045615301786, 'weight_decay': 0.0001028333394704652, 'batch_size': 128, 'activation': 'GELU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:17:26,744] Trial 36 pruned. \n",
      "[I 2024-11-03 17:17:27,089] Trial 37 pruned. \n",
      "[I 2024-11-03 17:18:18,588] Trial 38 finished with value: 1.0096515836715698 and parameters: {'hidden_size': 415, 'num_layers': 5, 'dropout_rate': 0.334126088251783, 'learning_rate': 0.0003645920158975084, 'weight_decay': 0.0022308158129154907, 'batch_size': 32, 'activation': 'GELU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:18:20,412] Trial 39 pruned. \n",
      "[I 2024-11-03 17:18:20,770] Trial 40 pruned. \n",
      "[I 2024-11-03 17:18:38,401] Trial 41 finished with value: 0.9921273856163025 and parameters: {'hidden_size': 289, 'num_layers': 5, 'dropout_rate': 0.17984034112972275, 'learning_rate': 0.0032353763499002154, 'weight_decay': 8.078485879154667e-05, 'batch_size': 128, 'activation': 'GELU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:18:51,325] Trial 42 pruned. \n",
      "[I 2024-11-03 17:19:08,960] Trial 43 finished with value: 1.0014368677139283 and parameters: {'hidden_size': 356, 'num_layers': 5, 'dropout_rate': 0.11480024802707656, 'learning_rate': 0.002306164877913548, 'weight_decay': 3.3788875275557154e-05, 'batch_size': 128, 'activation': 'GELU'}. Best is trial 3 with value: 0.9813557370503744.\n",
      "[I 2024-11-03 17:19:09,986] Trial 44 pruned. \n",
      "[I 2024-11-03 17:19:10,790] Trial 45 pruned. \n",
      "[I 2024-11-03 17:19:11,759] Trial 46 pruned. \n",
      "[I 2024-11-03 17:19:12,467] Trial 47 pruned. \n",
      "[I 2024-11-03 17:19:13,376] Trial 48 pruned. \n",
      "[I 2024-11-03 17:19:14,388] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Validation Loss: 0.98136\n",
      "  Best hyperparameters: {'hidden_size': 890, 'num_layers': 2, 'dropout_rate': 0.12161424428266182, 'learning_rate': 4.2052587410959206e-05, 'weight_decay': 2.8358340925720687e-05, 'batch_size': 32, 'activation': 'ReLU'}\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna Study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Validation Loss: {:.5f}'.format(trial.value))\n",
    "print('  Best hyperparameters: {}'.format(trial.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed80fcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:19:14.413904Z",
     "iopub.status.busy": "2024-11-03T17:19:14.413380Z",
     "iopub.status.idle": "2024-11-03T17:20:24.486209Z",
     "shell.execute_reply": "2024-11-03T17:20:24.485271Z"
    },
    "papermill": {
     "duration": 70.084759,
     "end_time": "2024-11-03T17:20:24.489123",
     "exception": false,
     "start_time": "2024-11-03T17:19:14.404364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Best Model\n",
    "best_params = trial.params\n",
    "activation = getattr(nn, best_params['activation'])()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        layers = []\n",
    "        in_features = input_dim\n",
    "        for _ in range(best_params['num_layers']):\n",
    "            layers.append(nn.Linear(in_features, best_params['hidden_size']))\n",
    "            layers.append(activation)\n",
    "            layers.append(nn.Dropout(best_params['dropout_rate']))\n",
    "            in_features = best_params['hidden_size']\n",
    "        layers.append(nn.Linear(best_params['hidden_size'], 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = NeuralNet(input_dim=X_train.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=best_params['learning_rate'],\n",
    "                        weight_decay=best_params['weight_decay'])\n",
    "batch_size = best_params['batch_size']\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49114f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T17:20:24.508190Z",
     "iopub.status.busy": "2024-11-03T17:20:24.507213Z",
     "iopub.status.idle": "2024-11-03T17:20:24.543540Z",
     "shell.execute_reply": "2024-11-03T17:20:24.542581Z"
    },
    "papermill": {
     "duration": 0.048455,
     "end_time": "2024-11-03T17:20:24.545840",
     "exception": false,
     "start_time": "2024-11-03T17:20:24.497385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_device = X_test_tensor.to(device)\n",
    "    predictions = model(X_test_device)\n",
    "    final_preds = predictions.cpu().numpy().squeeze()\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Hardness': final_preds\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8347608,
     "sourceId": 76849,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 479.250876,
   "end_time": "2024-11-03T17:20:26.116413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-03T17:12:26.865537",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
